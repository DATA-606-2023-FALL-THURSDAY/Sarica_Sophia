{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7246791f",
   "metadata": {},
   "source": [
    "# SL-RAT Score Degredation Prediction Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b0cc0",
   "metadata": {},
   "source": [
    "### STEP 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfec1b0",
   "metadata": {},
   "source": [
    "First, we will read a CSV file that contains the dataset with target and feature variables, and store it in a data frame named df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca42830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiasarica/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/sophiasarica/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943a3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SL_RAT_Final_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bb0263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>LINING_TYP</th>\n",
       "      <th>PIPE_SIZE</th>\n",
       "      <th>PIPE_MATER</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>UPSTREAM_I</th>\n",
       "      <th>DOWNSTREAM</th>\n",
       "      <th>time_since_install_da</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COLLECTOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>12.0</td>\n",
       "      <td>VITRIFIED CLAY PIPE</td>\n",
       "      <td>0.49</td>\n",
       "      <td>400.69</td>\n",
       "      <td>464.26</td>\n",
       "      <td>462.33</td>\n",
       "      <td>35725.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COLLECTOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>VITRIFIED CLAY PIPE</td>\n",
       "      <td>2.50</td>\n",
       "      <td>374.65</td>\n",
       "      <td>478.42</td>\n",
       "      <td>469.26</td>\n",
       "      <td>35725.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLLECTOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>VITRIFIED CLAY PIPE</td>\n",
       "      <td>2.00</td>\n",
       "      <td>301.28</td>\n",
       "      <td>390.86</td>\n",
       "      <td>384.75</td>\n",
       "      <td>35725.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COLLECTOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>15.0</td>\n",
       "      <td>VITRIFIED CLAY PIPE</td>\n",
       "      <td>0.40</td>\n",
       "      <td>51.09</td>\n",
       "      <td>10.14</td>\n",
       "      <td>9.93</td>\n",
       "      <td>26959.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLLECTOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>VITRIFIED CLAY PIPE</td>\n",
       "      <td>0.60</td>\n",
       "      <td>314.27</td>\n",
       "      <td>17.49</td>\n",
       "      <td>15.65</td>\n",
       "      <td>26959.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TYPE LINING_TYP  PIPE_SIZE           PIPE_MATER  SLOPE  LENGTH  \\\n",
       "0  COLLECTOR       NONE       12.0  VITRIFIED CLAY PIPE   0.49  400.69   \n",
       "1  COLLECTOR       NONE        8.0  VITRIFIED CLAY PIPE   2.50  374.65   \n",
       "2  COLLECTOR       NONE        8.0  VITRIFIED CLAY PIPE   2.00  301.28   \n",
       "3  COLLECTOR       NONE       15.0  VITRIFIED CLAY PIPE   0.40   51.09   \n",
       "4  COLLECTOR       NONE        8.0  VITRIFIED CLAY PIPE   0.60  314.27   \n",
       "\n",
       "   UPSTREAM_I  DOWNSTREAM  time_since_install_da  target  \n",
       "0      464.26      462.33                35725.0       1  \n",
       "1      478.42      469.26                35725.0       1  \n",
       "2      390.86      384.75                35725.0       1  \n",
       "3       10.14        9.93                26959.0       1  \n",
       "4       17.49       15.65                26959.0       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751ba0a",
   "metadata": {},
   "source": [
    "#### 1.1 Checking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c68cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TYPE                     0\n",
       "LINING_TYP               0\n",
       "PIPE_SIZE                0\n",
       "PIPE_MATER               0\n",
       "SLOPE                    0\n",
       "LENGTH                   0\n",
       "UPSTREAM_I               0\n",
       "DOWNSTREAM               0\n",
       "time_since_install_da    0\n",
       "target                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dee42f",
   "metadata": {},
   "source": [
    "### Step 2 : Further Exploratory Data Analysis\n",
    "\n",
    "The primary objective of this Exploratory Data Analysis (EDA) is to gain insights into the dataset for further modeling and hypothesis testing. We will focus on three main aspects:\n",
    "\n",
    "\n",
    "1. Distribution of Numerical Features\n",
    "2. Correlation Among Features\n",
    "3. Distribution of the Target Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4192ebc",
   "metadata": {},
   "source": [
    "Let's explore the data visually to understand the distributions and relationships among variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f019dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812b8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/nvf37c5d16q_mvzc8x76khdh0000gn/T/ipykernel_12397/3966929526.py:2: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.set_option('mode.use_inf_as_na', True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5bf879",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sl_rat_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2s/nvf37c5d16q_mvzc8x76khdh0000gn/T/ipykernel_12397/2385912925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming your DataFrame is named sl_rat_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl_rat_data\u001b[0m  \u001b[0;31m# Replace with the name of your DataFrame if different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Setting the aesthetics for the plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sl_rat_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting the aesthetics for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Distribution of numerical features\n",
    "numerical_features = ['PIPE_SIZE', 'SLOPE', 'LENGTH', 'UPSTREAM_I', 'DOWNSTREAM', 'time_since_install_da']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    sns.histplot(df[feature], bins=20, kde=True, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix among features\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5e5c4",
   "metadata": {},
   "source": [
    "### 2.1 Conclusion \n",
    "\n",
    "After conducting the Exploratory Data Analysis (EDA), here are the key observations and interpretations.\n",
    "\n",
    "####  Distribution of Numerical Features\n",
    "\n",
    "- **1**: Most of the pipe sizes center around 8 units.\n",
    "\n",
    "- **2**: Most slopes are less than 5, with a few exceptions.\n",
    "\n",
    "- **3**: The distribution appears fairly uniform, with a slight skew towards shorter lengths.\n",
    "\n",
    "- **4**: The distribution is slightly left-skewed, with most values around 300 to 400.\n",
    "\n",
    "- **5**: Similar to UPSTREAM_I, most values are around 300 to 400.\n",
    "- **6**: The distribution shows multiple peaks, indicating that installations occurred in different periods.\n",
    "\n",
    "---\n",
    "\n",
    "#### Correlation Matrix\n",
    "\n",
    "- **1**: None of the numerical features have a strong correlation with each other. \n",
    "- **2**: The highest correlation is between UPSTREAM_I and DOWNSTREAM with a value of 0.96, which is expected as they are related parameters.\n",
    "\n",
    "---\n",
    "\n",
    "#### Distribution of the Target Variable\n",
    "\n",
    "-  The target variable shows some imbalance with more instances of class 1 compared to class 0. \n",
    "-  This will need to be accounted for in the model training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9213ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0d6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creating a copy of the data to apply transformations\n",
    "data_transformed = sl_rat_data.copy()\n",
    "\n",
    "# Encoding string columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in data_transformed.columns:\n",
    "    if data_transformed[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        data_transformed[column] = le.fit_transform(data_transformed[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Splitting the transformed data into features and target\n",
    "X_transformed = data_transformed.drop('target', axis=1)\n",
    "y_transformed = data_transformed['target']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_transformed, X_test_transformed, y_train_transformed, y_test_transformed = train_test_split(\n",
    "    X_transformed, y_transformed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Applying RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_transformed, y_train_transformed)\n",
    "y_pred_transformed = rf_classifier.predict(X_test_transformed)\n",
    "\n",
    "# Evaluating the classifier\n",
    "rf_accuracy = accuracy_score(y_test_transformed, y_pred_transformed)\n",
    "rf_precision = precision_score(y_test_transformed, y_pred_transformed, average='weighted')\n",
    "rf_recall = recall_score(y_test_transformed, y_pred_transformed, average='weighted')\n",
    "rf_f1 = f1_score(y_test_transformed, y_pred_transformed, average='weighted')\n",
    "\n",
    "rf_scores = {\n",
    "    'accuracy': rf_accuracy,\n",
    "    'precision': rf_precision,\n",
    "    'recall': rf_recall,\n",
    "    'f1': rf_f1\n",
    "}\n",
    "\n",
    "rf_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0253ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae663767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81518d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b2a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd3cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1236ee07",
   "metadata": {},
   "source": [
    "### STEP 3 : Data Preprocessing \n",
    "\n",
    "### Encoding Categorical Variables, Scaling the Features and Handling Imbalanced Target Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries again to ensure everything is in place\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Re-run the data preprocessing steps\n",
    "\n",
    "# Step 1: Encoding Categorical Variables using One-Hot Encoding\n",
    "categorical_cols = ['TYPE', 'LINING_TYP', 'PIPE_MATER']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Step 2: Feature Scaling using Standard Scaling on Numerical Features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['PIPE_SIZE', 'SLOPE', 'LENGTH', 'UPSTREAM_I', 'DOWNSTREAM', 'time_since_install_da']\n",
    "\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "# Step 3: Handling Imbalanced Data using Pandas (Oversampling the minority class)\n",
    "# Separate the majority and minority classes\n",
    "df_majority = df_encoded[df_encoded.target==1]\n",
    "df_minority = df_encoded[df_encoded.target==0]\n",
    "\n",
    "# Oversample the minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,                # Sample with replacement\n",
    "                                 n_samples=len(df_majority),  # Match the number in majority class\n",
    "                                 random_state=42)             # Reproducible results\n",
    "\n",
    "# Combine the majority class with the upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Confirm that the dataset is balanced and encoded based on the newly defined categorical columns\n",
    "df_upsampled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc0358",
   "metadata": {},
   "source": [
    "### 3.1 Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib and seaborn for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define numerical and categorical columns again for clarity\n",
    "numerical_cols = ['PIPE_SIZE', 'SLOPE', 'LENGTH', 'UPSTREAM_I', 'DOWNSTREAM', 'time_since_install_da']\n",
    "categorical_cols = ['TYPE', 'LINING_TYP', 'PIPE_MATER']\n",
    "\n",
    "# Plot the distribution of numerical features after scaling\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "for i, feature in enumerate(numerical_cols):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    sns.histplot(df_encoded[feature], bins=20, kde=True, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Distribution of {feature} (After Scaling)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of the target variable after balancing\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='target', data=df_upsampled)\n",
    "plt.title('Distribution of Target Variable (After Balancing)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd54009",
   "metadata": {},
   "source": [
    "### 3.2 Visual Summary:\n",
    "\n",
    "#### Distribution of Numerical Features (After Scaling):\n",
    "- All numerical features now appear to be centered around zero, confirming that standard scaling has been applied.\n",
    "- The distributions remain the same as before scaling; only the scale has changed.\n",
    "\n",
    "#### Distribution of Target Variable (After Balancing):\n",
    "- The target variable shows a balanced distribution with 902 instances for both class 0 and class 1.\n",
    "- In oversampling, instances of the minority class are randomly replicated to balance the number of each class in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25047924",
   "metadata": {},
   "source": [
    "### STEP 4 : Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdefc771",
   "metadata": {},
   "source": [
    "### 4.1 : Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5baf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries again to ensure everything is in place\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036851ae",
   "metadata": {},
   "source": [
    "### 4.2 : Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c24aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection and training\n",
    "\n",
    "# Splitting the balanced and preprocessed data into train and test sets\n",
    "X_balanced = df_upsampled.drop('target', axis=1)\n",
    "y_balanced = df_upsampled['target']\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the balanced training set\n",
    "rf_classifier.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_balanced = rf_classifier.predict(X_test_balanced)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test_balanced, y_pred_balanced)\n",
    "classification_rep = classification_report(y_test_balanced, y_pred_balanced, output_dict=True)\n",
    "\n",
    "# Convert the classification report to a DataFrame for better visualization\n",
    "classification_report_df = pd.DataFrame(classification_rep).transpose()\n",
    "\n",
    "accuracy, classification_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eee55c",
   "metadata": {},
   "source": [
    "### 4.3 Model Evaluation Summary \n",
    "\n",
    "| Metric/Class  | Precision  | Recall  | F1-Score  | Support  |\n",
    "|---------------|------------|---------|-----------|----------|\n",
    "| 0             | 85.4%      | 90.0%   | 87.6%     | 279      |\n",
    "| 1             | 88.7%      | 83.7%   | 86.1%     | 263      |\n",
    "| **Accuracy**  | **86.9%**  | **86.9%** | **86.9%** | **N/A**  |\n",
    "| Macro Avg     | 87.0%      | 86.8%   | 86.9%     | 542      |\n",
    "| Weighted Avg  | 87.0%      | 86.9%   | 86.9%     | 542      |\n",
    "\n",
    "#### Interpretation and Explanation:\n",
    "\n",
    "- **Precision**: The model is 85.4% precise for class 0 and 88.7% for class 1.\n",
    "  \n",
    "- **Recall**: The model has a recall of 90.0% for class 0 and 83.7% for class 1.\n",
    "  \n",
    "- **F1-Score**: The F1-score for class 0 is 87.6% and for class 1 is 86.1%.\n",
    "  \n",
    "- **Accuracy**: The overall accuracy of the model is 86.9%.\n",
    "  \n",
    "- **Macro and Weighted Avg**: These are averages of the above metrics, considering both classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f02e8",
   "metadata": {},
   "source": [
    "### 4.3 Visual Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for visual analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_balanced, y_pred_balanced)\n",
    "\n",
    "# Visualizing the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec620cd",
   "metadata": {},
   "source": [
    "### 4.4 Interpretation of Confusion Matrix\n",
    "\n",
    "- **Top Left (True Negative)**: 251 samples were correctly classified as Class 0.\n",
    "- **Top Right (False Positive)**: 28 samples were incorrectly classified as Class 1 when they were actually Class 0.\n",
    "- **Bottom Left (False Negative)**: 43 samples were incorrectly classified as Class 0 when they were actually Class 1.\n",
    "- **Bottom Right (True Positive)**: 220 samples were correctly classified as Class 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107a2de",
   "metadata": {},
   "source": [
    " We can use Grid Search with Cross-Validation to find the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5658e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38646c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c31bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cb2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695bc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
